<!DOCTYPE html>
<html lang="en-us">
  <head>

    <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
    <link rel="manifest" href="/images/site.webmanifest">

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="My personal blog.">
    <title>AWS with Terraform tutorial 07 | home</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    <link rel="stylesheet" href="/css/theme-override.css">
    
  </head>

  <body>
    <header>
      <nav>
        <ul>
          
          
          <li class="pull-left ">
            <a href="/">~/home</a>
          </li>
          
          
          <li class="pull-left ">
            <a href="https://github.com/richardpct">~/github</a>
          </li>
          
          
          <li class="pull-left ">
            <a href="https://www.linkedin.com/in/richard-phan-chan-the/">~/linkedin</a>
          </li>
          

          

        </ul>
      </nav>
    </header>


<div class="article-meta">
<h1><span class="title">AWS with Terraform tutorial 07</span></h1>

<h2 class="date">2021/04/17</h2>
<p class="terms">
  
  
  
  
  
</p>
</div>



<div class="content-wrapper">
  <main>
    <h2 id="purpose">Purpose</h2>
<p>This tutorial takes up the previous one
<a href="https://richardpct.github.io/post/2021/04/05/aws-with-terraform-tutorial-06/">aws-terraform-tuto06</a>
by adding an ALB (Application Load Balancer) in front of the 2 web servers for
sharing the load between 2 web servers and having a short downtime when a web
server is failing.</p>
<p>The following figure depicts the infrastructure you will build:</p>
<div style="text-align: center;">
  <img src="https://raw.githubusercontent.com/richardpct/images/master/aws-tuto-07/image01.png">
</div>
<p>The source code can be found <a href="https://github.com/richardpct/aws-terraform-tuto07">here</a>.</p>
<h2 id="configuring-the-network">Configuring the network</h2>
<h4 id="environmentsdev00-basemaintf">environments/dev/00-base/main.tf</h4>
<p>The following code shows how the subnets are configured:</p>
<pre tabindex="0"><code>module &#34;base&#34; {
  source = &#34;../../../modules/base&#34;

  region                  = &#34;eu-west-3&#34;
  env                     = &#34;dev&#34;
  vpc_cidr_block          = &#34;10.0.0.0/16&#34;
  subnet_public_lb_a      = &#34;10.0.0.0/24&#34;
  subnet_public_lb_b      = &#34;10.0.1.0/24&#34;
  subnet_public_nat_a     = &#34;10.0.2.0/24&#34;
  subnet_public_nat_b     = &#34;10.0.3.0/24&#34;
  subnet_public_bastion_a = &#34;10.0.4.0/24&#34;
  subnet_public_bastion_b = &#34;10.0.5.0/24&#34;
  subnet_private_web_a    = &#34;10.0.6.0/24&#34;
  subnet_private_web_b    = &#34;10.0.7.0/24&#34;
  subnet_private_redis_a  = &#34;10.0.8.0/24&#34;
  subnet_private_redis_b  = &#34;10.0.9.0/24&#34;
  cidr_allowed_ssh        = var.my_ip_address
  ssh_public_key          = var.ssh_public_key
}
</code></pre><p>As you can see each service is held into 2 subnets, the first is located in the
Availability Zone A and the second in Availability Zone B.<br />
The load balancer, the Nat gateway and the bastion run in the public subnet
whereas the web server, redis server run in the private subnet.</p>
<h4 id="modulesbasenetworktf">modules/base/network.tf</h4>
<p>We create a Nat Gateway in each Availability Zone, the private services located
in the AZ-A will use the Nat Gateway in AZ-A, likewise the private services
located in the AZ-B will use the Nat Gateway in AZ-B, thus if a AZ is
unavailable the service still works:</p>
<pre tabindex="0"><code>resource &#34;aws_eip&#34; &#34;nat_a&#34; {
  vpc = true

  tags = {
    Name = &#34;eip_nat_a-${var.env}&#34;
  }
}

resource &#34;aws_eip&#34; &#34;nat_b&#34; {
  vpc = true

  tags = {
    Name = &#34;eip_nat_b-${var.env}&#34;
  }
}

resource &#34;aws_nat_gateway&#34; &#34;nat_gw_a&#34; {
  allocation_id = aws_eip.nat_a.id
  subnet_id     = aws_subnet.public_nat_a.id

  tags = {
    Name = &#34;nat_gw_a-${var.env}&#34;
  }
}

resource &#34;aws_nat_gateway&#34; &#34;nat_gw_b&#34; {
  allocation_id = aws_eip.nat_b.id
  subnet_id     = aws_subnet.public_nat_b.id

  tags = {
    Name = &#34;nat_gw_b-${var.env}&#34;
  }
}
</code></pre><p>I remind you that the public subnets use a default route to the Internet
Gateway whereas the private subnet use a default route to the Nat Gateway:</p>
<pre tabindex="0"><code>resource &#34;aws_route_table_association&#34; &#34;public_lb_a&#34; {
  subnet_id      = aws_subnet.public_lb_a.id
  route_table_id = aws_route_table.route.id
}

resource &#34;aws_route_table_association&#34; &#34;public_lb_b&#34; {
  subnet_id      = aws_subnet.public_lb_b.id
  route_table_id = aws_route_table.route.id
}

resource &#34;aws_route_table_association&#34; &#34;public_nat_a&#34; {
  subnet_id      = aws_subnet.public_nat_a.id
  route_table_id = aws_route_table.route.id
}

resource &#34;aws_route_table_association&#34; &#34;public_nat_b&#34; {
  subnet_id      = aws_subnet.public_nat_b.id
  route_table_id = aws_route_table.route.id
}

resource &#34;aws_route_table_association&#34; &#34;public_bastion_a&#34; {
  subnet_id      = aws_subnet.public_bastion_a.id
  route_table_id = aws_route_table.route.id
}

resource &#34;aws_route_table_association&#34; &#34;public_bastion_b&#34; {
  subnet_id      = aws_subnet.public_bastion_b.id
  route_table_id = aws_route_table.route.id
}

resource &#34;aws_route_table_association&#34; &#34;private_web_a&#34; {
  subnet_id      = aws_subnet.private_web_a.id
  route_table_id = aws_route_table.route_nat_a.id
}

resource &#34;aws_route_table_association&#34; &#34;private_web_b&#34; {
  subnet_id      = aws_subnet.private_web_b.id
  route_table_id = aws_route_table.route_nat_b.id
}
</code></pre><p>Except the Nat Gateway, only the bastion requires an Elastic IP, the web
servers don&rsquo;t need it anymore because a public IP will automatically assign to
the Load Balancer:</p>
<pre tabindex="0"><code>resource &#34;aws_eip&#34; &#34;nat_a&#34; {
  vpc = true

  tags = {
    Name = &#34;eip_nat_a-${var.env}&#34;
  }
}

resource &#34;aws_eip&#34; &#34;nat_b&#34; {
  vpc = true

  tags = {
    Name = &#34;eip_nat_b-${var.env}&#34;
  }
}

resource &#34;aws_eip&#34; &#34;bastion&#34; {
  vpc = true

  tags = {
    Name = &#34;eip_bastion-${var.env}&#34;
  }
}
</code></pre><h2 id="creating-the-load-balancer">Creating the Load Balancer</h2>
<h4 id="modulesbasealbtf">modules/base/alb.tf</h4>
<p>We create our Application Load Balancer assigned in 2 public subnets:</p>
<pre tabindex="0"><code>resource &#34;aws_lb&#34; &#34;web&#34; {
  name               = &#34;alb-web-${var.env}&#34;
  internal           = false
  load_balancer_type = &#34;application&#34;
  security_groups    = [aws_security_group.alb_web.id]
  subnets            = [aws_subnet.public_lb_a.id, aws_subnet.public_lb_b.id]
}
</code></pre><p>We state the behavior of our Load Balancer, it forwards the requests to port
8000 of the web servers and check the health of our service by using the page
located at /cgi-bin/ping.py (you will see later how this script is created),
and the Load Balancer receives the requests in port 80:</p>
<pre tabindex="0"><code>resource &#34;aws_lb_target_group&#34; &#34;web&#34; {
  port     = 8000
  protocol = &#34;HTTP&#34;
  vpc_id   = aws_vpc.my_vpc.id

  health_check {
    healthy_threshold   = 2
    unhealthy_threshold = 2
    timeout             = 3
    interval            = 30
    path                = &#34;/cgi-bin/ping.py&#34;
  }
}

resource &#34;aws_lb_listener&#34; &#34;web&#34; {
  load_balancer_arn = aws_lb.web.arn
  port              = 80
  protocol          = &#34;HTTP&#34;

  default_action {
    target_group_arn = aws_lb_target_group.web.arn
    type             = &#34;forward&#34;
  }
}
</code></pre><h2 id="configuring-the-web-servers">Configuring the Web Servers</h2>
<h4 id="moduleswebservermaintf">modules/webserver/main.tf</h4>
<p>We create an autoscaling group associated with our Load Balancer to ensure that
we have 2 servers up and running, if a server is failing for any reasons, it
will stop receiving the requests, afterwards it will be replaced by a new one:</p>
<pre tabindex="0"><code>resource &#34;aws_autoscaling_group&#34; &#34;web&#34; {
  name                 = &#34;asg_web-${var.env}&#34;
  launch_configuration = aws_launch_configuration.web.id
  vpc_zone_identifier  = [data.terraform_remote_state.base.outputs.subnet_private_web_a_id, data.terraform_remote_state.base.outputs.subnet_private_web_b_id]
  target_group_arns    = [data.terraform_remote_state.base.outputs.alb_target_group_web_arn]
  health_check_type    = &#34;ELB&#34;

  min_size             = 2
  max_size             = 2

  tag {
    key                 = &#34;Name&#34;
    value               = &#34;webserver-${var.env}&#34;
    propagate_at_launch = true
  }
}
</code></pre><h4 id="moduleswebserveruser-datash">modules/webserver/user-data.sh</h4>
<p>I added a page located at /cgi-bin/ping.py for checking the health of the web
servers, in addition I display the instance Id:</p>
<pre tabindex="0"><code>#!/bin/bash

set -x

exec &gt; &gt;(tee /var/log/user-data.log|logger -t user-data -s 2&gt;/dev/console) 2&gt;&amp;1
sudo yum -y update
sudo yum -y upgrade
sudo yum -y install python38
sudo pip-3.8 install redis
sudo useradd www -s /sbin/nologin
mkdir -p /var/lib/www/cgi-bin
INSTANCE_ID=&#34;$(curl -s http://169.254.169.254/latest/meta-data/instance-id)&#34;

cat &lt;&lt; EOF &gt; /var/lib/www/cgi-bin/hello.py
#!/usr/bin/env python3

import redis

r = redis.Redis(
                host=&#39;${database_host}&#39;,
                port=6379)
r.set(&#39;count&#39;, 0)
count = r.incr(1)

print(&#34;Content-type: text/html&#34;)
print(&#34;&#34;)
print(&#34;&lt;html&gt;&lt;body&gt;&#34;)
print(&#34;&lt;p&gt;Hello World!&lt;br /&gt;counter: &#34; + str(count) + &#34;&lt;br /&gt;env: ${environment}&lt;/p&gt;&#34;)
print(&#34;Id: $INSTANCE_ID&#34;)
print(&#34;&lt;/body&gt;&lt;/html&gt;&#34;)
EOF

cat &lt;&lt; EOF &gt; /var/lib/www/cgi-bin/ping.py
#!/usr/bin/env python

import redis

r = redis.Redis(
                host=&#39;${database_host}&#39;,
                port=6379)
r.set(&#39;count&#39;, 0)
count = r.incr(1)

print(&#34;Content-type: text/html&#34;)
print(&#34;&#34;)
print(&#34;&lt;html&gt;&lt;body&gt;&#34;)
print(&#34;&lt;p&gt;Hello World!&lt;br /&gt;counter: &#34; + str(count) + &#34;&lt;br /&gt;env: ${environment}&lt;/p&gt;&#34;)
print(&#34;Id: $INSTANCE_ID&#34;)
print(&#34;&lt;/body&gt;&lt;/html&gt;&#34;)
EOF

cat &lt;&lt; EOF &gt; /var/lib/www/cgi-bin/ping.py
#!/usr/bin/env python3

print(&#34;Content-type: text/html&#34;)
print(&#34;&#34;)
print(&#34;&lt;html&gt;&lt;body&gt;&#34;)
print(&#34;&lt;p&gt;ok&lt;/p&gt;&#34;)
print(&#34;&lt;/body&gt;&lt;/html&gt;&#34;)
EOF

chmod 755 /var/lib/www/cgi-bin/hello.py
chmod 755 /var/lib/www/cgi-bin/ping.py
cd /var/lib/www
sudo -u www python3 -m http.server 8000 --cgi
</code></pre><h2 id="deploying-the-infrastructure">Deploying the infrastructure</h2>
<p>Export the following environment variables:</p>
<pre><code>$ export TF_VAR_region=&quot;eu-west-3&quot;
$ export TF_VAR_bucket=&quot;yourbucket-terraform-state&quot;
$ export TF_VAR_dev_base_key=&quot;terraform/dev/base/terraform.tfstate&quot;
$ export TF_VAR_dev_bastion_key=&quot;terraform/dev/bastion/terraform.tfstate&quot;
$ export TF_VAR_dev_database_key=&quot;terraform/dev/database/terraform.tfstate&quot;
$ export TF_VAR_dev_webserver_key=&quot;terraform/dev/webserver/terraform.tfstate&quot;
$ export TF_VAR_ssh_public_key=&quot;ssh-rsa XXX...&quot;
$ export TF_VAR_my_ip_address=$(curl -s 'https://duckduckgo.com/?q=ip&amp;t=h_&amp;ia=answer' \
| sed -e 's/.*Your IP address is \([0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}\) in.*/\1/')
</code></pre>
<p>Building:</p>
<pre><code>$ cd environments/dev
$ cd 00-network
$ terraform init \
    -backend-config=&quot;bucket=${TF_VAR_bucket}&quot; \
    -backend-config=&quot;key=${TF_VAR_dev_network_key}&quot; \
    -backend-config=&quot;region=${TF_VAR_region}&quot;
$ terraform apply
$ cd ../01-bastion
$ terraform init \
    -backend-config=&quot;bucket=${TF_VAR_bucket}&quot; \
    -backend-config=&quot;key=${TF_VAR_dev_bastion_key}&quot; \
    -backend-config=&quot;region=${TF_VAR_region}&quot;
$ terraform apply
$ cd ../02-database
$ terraform init \
    -backend-config=&quot;bucket=${TF_VAR_bucket}&quot; \
    -backend-config=&quot;key=${TF_VAR_dev_database_key}&quot; \
    -backend-config=&quot;region=${TF_VAR_region}&quot;
$ terraform apply
$ cd ../03-webserver
$ terraform init \
    -backend-config=&quot;bucket=${TF_VAR_bucket}&quot; \
    -backend-config=&quot;key=${TF_VAR_dev_webserver_key}&quot; \
    -backend-config=&quot;region=${TF_VAR_region}&quot;
$ terraform apply
</code></pre>
<p>You need to perform <code>terraform init</code> once.</p>
<h2 id="testing-your-infrastructure">Testing your infrastructure</h2>
<p>When your infrastructure is built, get the DNS name of your Load Balancer by
performing the following command:</p>
<pre><code>$ aws elbv2 describe-load-balancers --names alb-web-dev \
    --query 'LoadBalancers[*].DNSName' \
    --output text
</code></pre>
<p>Get the ARN of your Load Balancer:</p>
<pre><code>$ aws elbv2 describe-load-balancers --names alb-web-dev \
    --query 'LoadBalancers[*].LoadBalancerArn' \
    --output text
</code></pre>
<p>Get the ARN of your Target Groups by providing the Load Balancer ARN:</p>
<pre><code>$ aws elbv2 describe-target-groups \
    --load-balancer-arn arn:aws:elasticloadbalancing:eu-west-3:xxxxxxxxxxxx:loadbalancer/app/alb-web-dev/xxxxxxxxxxxxxxxx \
    --query 'TargetGroups[*].TargetGroupArn' \
    --output text
</code></pre>
<p>Perform the following command by providing the Target Group ARN until you have
2 healthy instances:</p>
<pre><code>$ aws elbv2 describe-target-health \
    --target-group-arn arn:aws:elasticloadbalancing:eu-west-3:xxxxxxxxxxxx:targetgroup/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
</code></pre>
<p>Then issue the following command several times for increasing the counter:</p>
<pre><code>$ curl http://ARN_load_balancer:8000/cgi-bin/hello.py
</code></pre>
<p>It should return the count of requests you have performed.</p>
<h2 id="testing-the-high-availability">Testing the High Availability</h2>
<p>Chose one of the 2 running instances and connect to it, then kill the web
service process:</p>
<pre><code>$ ssh -J ec2-user@IP_public_bastion ec2-user@IP_private_instance
$ sudo su -
# pkill python3
</code></pre>
<p>Wait for a while, then the Load Balancer will deregister the unhealthy instance,
you now have only one healthy instance:</p>
<pre><code>$ aws elbv2 describe-target-health \
    --target-group-arn arn:aws:elasticloadbalancing:eu-west-3:xxxxxxxxxxxx:targetgroup/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
</code></pre>
<p>If you make some requests to the service, you will notice it is still up and
running because the Load Balancer have stopped to forward to the failed server,
only the healthy server is used:</p>
<pre><code>$ curl http://ARN_load_balancer:8000/cgi-bin/hello.py
</code></pre>
<p>Wait for a while, then you will have 2 healthy instances because a new one has
replaced the failed instance.</p>
<h2 id="destroying-your-infrastructure">Destroying your infrastructure</h2>
<p>After finishing your test, destroy your infrastructure:</p>
<pre><code>$ cd environments/dev
$ cd 03-webserver
$ terraform destroy
$ cd ../02-database
$ terraform destroy
$ cd ../01-bastion
$ terraform destroy
$ cd ../00-network
$ terraform destroy
</code></pre>

    <a href="/"> >> Home</a>
  </main>
</div>
    <footer>
      
      
      <script>
      (function() {
        function center_el(tagName) {
          var tags = document.getElementsByTagName(tagName), i, tag;
          for (i = 0; i < tags.length; i++) {
            tag = tags[i];
            var parent = tag.parentElement;
            
            if (parent.childNodes.length === 1) {
              
              if (parent.nodeName === 'A') {
                parent = parent.parentElement;
                if (parent.childNodes.length != 1) continue;
              }
              if (parent.nodeName === 'P') parent.style.textAlign = 'center';
            }
          }
        }
        var tagNames = ['img', 'embed', 'object'];
        for (var i = 0; i < tagNames.length; i++) {
          center_el(tagNames[i]);
        }
      })();
      </script>

      
      <hr/>
      © 2026 · Powered by the <a href="https://github.com/goodroot/hugo-classic">Classic theme</a> for <a href="https://gohugo.io/">Hugo</a>.
      
    </footer>
  </body>
</html>

